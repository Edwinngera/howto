###########################################################
#
#   Learn in 5 minutes [Apache Hadoop]
#	learn_in_5minutes_db_apache_hadoop.txt
#
###########################################################




# Installing Software
sudo apt-get install ssh
sudo apt-get install rsync


# Prepare to Start the Hadoop Cluster
wget http://apache.lauf-forum.at/hadoop/common/hadoop-3.1.1/hadoop-3.1.1.tar.gz
# set to the root of your Java installation
export JAVA_HOME=/usr/java/latest


# start
bin/hadoop


# Standalone Operation
mkdir input
cp etc/hadoop/*.xml input
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar grep input output 'dfs[a-z.]+'
cat output/*



# Execution
bin/hdfs namenode -format # Format the filesystem
sbin/start-dfs.sh   # Start NameNode daemon and DataNode daemon

# Make the HDFS directories required to execute MapReduce job
bin/hdfs dfs -mkdir /user
bin/hdfs dfs -mkdir /user/<username>

# Copy the input files into the distributed filesystem
bin/hdfs dfs -put etc/hadoop input

# Run some of the examples provided
bin/hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.9.1.jar grep input output 'dfs[a-z.]+'



# Examine the output files
bin/hdfs dfs -get output output
cat output/*
bin/hdfs dfs -cat output/*

# When youâ€™re done, stop the daemons
sbin/stop-dfs.sh




http://hadoop.apache.org/
http://hadoop.apache.org/docs/stable/
http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html
http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/ClusterSetup.html
http://www.apache.org/dyn/closer.cgi/hadoop/common/
http://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-common/SingleCluster.html#Standalone_Operation
